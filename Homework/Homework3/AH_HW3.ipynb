{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97e2ff1-c6f7-486e-a457-5ee652dd0812",
   "metadata": {},
   "source": [
    "Allen Hoskins\n",
    "\n",
    "DS7337: Natural Language Processing, Fall 2022\n",
    "\n",
    "# <u>Homework 3</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151d09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages \n",
    "\n",
    "import numpy as np\n",
    "from nltk.metrics import edit_distance\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96d4488-4493-4f0f-8151-52f8875dd179",
   "metadata": {},
   "source": [
    "***\n",
    "### 1. Compare your given name with your nickname (if you don’t have a nickname, invent one for this assignment) by answering the following questions:\n",
    "a. What is the edit distance between your nickname and your given name? \n",
    "> The edit distance between my nickname and given name is 9.\n",
    "\n",
    "b. What is the percentage string match between your nickname and your given name?\n",
    "Show your work for both calculations.\n",
    "> The percentage string match using `difflib's` `SequenceMatcher` is 47.06%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0627386-7d34-4a32-8355-fc9ddf770bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The edit Distance between \"Allen Hoskins\" and \"Hosk\" is: 9\n"
     ]
    }
   ],
   "source": [
    "s1 = 'Allen Hoskins'\n",
    "s2 = 'Hosk'\n",
    "dist = edit_distance(s1, s2, substitution_cost=1, transpositions=False)\n",
    "\n",
    "print(f'The edit Distance between \"{s1}\" and \"{s2}\" is: {dist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5be209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent string match between \"Allen Hoskins\" and \"Hosk\" is: 0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "perc = SequenceMatcher(a=s1, b=s2).ratio()\n",
    "\n",
    "print(f'The percent string match between \"{s1}\" and \"{s2}\" is: {perc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd32f684-f9da-4b94-a50e-3f92fbb0a483",
   "metadata": {},
   "source": [
    "***\n",
    "### 2. Find a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f249b",
   "metadata": {},
   "source": [
    "> I chose the beginning two sentences of `Moby Dick`. When removing stop words my friend was able to determine the book and guess `Moby Dick` correctly. I believe they were able to determine the book due to the fact that `Call me Ishmael` is a very famous first line to a book. If `Ishmael` was not in the output of the filtered words, this text would be significantly harder to guess.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75bbf092-ff58-4f8d-9f84-7d3128674874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'Ishmael', 'Some', 'years', 'ago—never', 'mind', 'long', 'precisely—having', 'little', 'money', 'purse', 'nothing', 'particular', 'interest', 'shore', 'I', 'thought', 'I', 'would', 'sail', 'little', 'see', 'watery', 'part', 'world']\n"
     ]
    }
   ],
   "source": [
    "sent = 'Call me Ishmael. Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world.'\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "  \n",
    "word_tokens = word_tokenize(sent)\n",
    "\n",
    "punct = punctuation\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "  \n",
    "filtered_sentence = []\n",
    "  \n",
    "for w in word_tokens:\n",
    "    if w not in stop_words and w not in punct:\n",
    "        filtered_sentence.append(w)\n",
    "  \n",
    "#print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b74d0-febf-4b3d-857c-3932ab50917c",
   "metadata": {},
   "source": [
    "***\n",
    "### 3. Run one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage.\n",
    "\n",
    ">The chosen stemmer was Snowball, which is an update to the popular Porter Stemmer. Snowball produced 24 stemmed words and with a 75% accuracy of valid morphological root identification (18 words).\n",
    "\n",
    ">Porter and Lancaster stemmers were also triend and returned the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592fdafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming using Snowball Stemmer:\n",
      "-----------------------------------------------------------------\n",
      "Call  :  call\n",
      "Ishmael  :  ishmael\n",
      "Some  :  some\n",
      "years  :  year\n",
      "ago—never  :  ago—nev\n",
      "mind  :  mind\n",
      "long  :  long\n",
      "precisely—having  :  precisely—hav\n",
      "little  :  littl\n",
      "money  :  money\n",
      "purse  :  purs\n",
      "nothing  :  noth\n",
      "particular  :  particular\n",
      "interest  :  interest\n",
      "shore  :  shore\n",
      "I  :  i\n",
      "thought  :  thought\n",
      "I  :  i\n",
      "would  :  would\n",
      "sail  :  sail\n",
      "little  :  littl\n",
      "see  :  see\n",
      "watery  :  wateri\n",
      "part  :  part\n",
      "world  :  world\n"
     ]
    }
   ],
   "source": [
    "sno = SnowballStemmer('english')\n",
    "\n",
    "print('Stemming using Snowball Stemmer:')\n",
    "print(\"-\"*65)\n",
    "for w in filtered_sentence:\n",
    "    print(w, \" : \", sno.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d5512-d8d3-4c0e-ad89-f2eb46735e0f",
   "metadata": {},
   "source": [
    "***\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06592950-f388-4bef-a334-c99f433d21c4",
   "metadata": {},
   "source": [
    "Edit Distance: https://www.nltk.org/api/nltk.metrics.distance.html#nltk.metrics.distance.edit_distance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "76cbc1d22d2ec03295cd5a8ae680c721667c569897428aaeeb69f9305902a57b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tag,word_tokenize,pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 1\n",
    "1. Run one of the part-of-speech (POS) taggers available in Python. \n",
    "> a. Find the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "\n",
    "> b. Find the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n",
    "\n",
    "The short setence that was used was \"The robber eats, shoots and leaves.\" This is a  play on the commonly used setence \"The pandas eats, shoots and leaves\" which is used to describe the importance of oxford commas. Since shoots and leaves can be both nounds and verbs, the tagger has difficulty correclty tagging the sentence. It currently taggs `shoots` and `leaves` as plural nounds, but in the context of the sentence they should be verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_sentence = 'Their plots were failing because of some important friends of the king.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Sentence NLTK Tagging:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Their', 'PRP$'),\n",
       " ('plots', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('failing', 'VBG'),\n",
       " ('because', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('important', 'JJ'),\n",
       " ('friends', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('king', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_tagged = pos_tag(word_tokenize(long_sentence))\n",
    "print('Long Sentence NLTK Tagging:\\n')\n",
    "ls_tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_setence = 'The robber eats, shoots and leaves.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Sentence NLTK Tagging:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('robber', 'NN'),\n",
       " ('eats', 'NNS'),\n",
       " (',', ','),\n",
       " ('shoots', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('leaves', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_tagged = pos_tag(word_tokenize(short_setence))\n",
    "print('Short Sentence NLTK Tagging:\\n')\n",
    "ss_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 2\n",
    "\n",
    "2. Run a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "> a. Does it produce the same or different output? \n",
    "\n",
    "When running the tagger from the python package `SpaCy`, the long sentence is tagged the same way as `nltk` tagged it, however in the short setence the word `eats` is correctly tagged when using `SpaCy` but not when utilizing `nltk.`\n",
    "\n",
    "> b. Explain any differences as best you can.\n",
    "\n",
    "I'm not 100% sure why `nltk` would incorrectly tag the word `eats`, but due to the complexity of this setence it is expected to struggle to correctly tag `shoots` and `leaves`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Sentence SpaCy taggging:\n",
      "\n",
      "Their        PRON       PRP$     pronoun, possessive\n",
      "plots        NOUN       NNS      noun, plural\n",
      "were         AUX        VBD      verb, past tense\n",
      "failing      VERB       VBG      verb, gerund or present participle\n",
      "because      SCONJ      IN       conjunction, subordinating or preposition\n",
      "of           ADP        IN       conjunction, subordinating or preposition\n",
      "some         DET        DT       determiner\n",
      "important    ADJ        JJ       adjective (English), other noun-modifier (Chinese)\n",
      "friends      NOUN       NNS      noun, plural\n",
      "of           ADP        IN       conjunction, subordinating or preposition\n",
      "the          DET        DT       determiner\n",
      "king         NOUN       NN       noun, singular or mass\n",
      ".            PUNCT      .        punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "spacy_long = sp('Their plots were failing because of some important friends of the king.')\n",
    "print('Long Sentence SpaCy taggging:\\n')\n",
    "for word in spacy_long:\n",
    "    print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Sentence SpaCy taggging:\n",
      "\n",
      "The          DET        DT       determiner\n",
      "panda        NOUN       NN       noun, singular or mass\n",
      "eats         VERB       VBZ      verb, 3rd person singular present\n",
      ",            PUNCT      ,        punctuation mark, comma\n",
      "shoots       NOUN       NNS      noun, plural\n",
      "and          CCONJ      CC       conjunction, coordinating\n",
      "leaves       NOUN       NNS      noun, plural\n",
      ".            PUNCT      .        punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "spacy_short = sp('The panda eats, shoots and leaves.')\n",
    "print('Short Sentence SpaCy taggging:\\n')\n",
    "for word in spacy_short:\n",
    "    print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "# Part 3\n",
    "3. In a news article from this weekâ€™s news, find a random sentence of at least 10 words.\n",
    "> a. Looking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "<url>https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html</url>\n",
    "\n",
    "> b. Now run the same sentences through both taggers that you implemented for questions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = 'Google discontinued its Google Translate service in mainland China citing low usage.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Own tagging from Penn tag set: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Google', 'NNP'),\n",
       " ('discountinued', 'VBD'),\n",
       " ('its', 'PRP$'),\n",
       " ('Google', 'NNP'),\n",
       " ('Translate', 'NNP'),\n",
       " ('service', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('mainland', 'JJ'),\n",
       " ('China', 'NNP'),\n",
       " ('citing', 'VBG'),\n",
       " ('low', 'JJ'),\n",
       " ('usage', 'NN'),\n",
       " ('.', 'SYM')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "own_tag =   [(\"Google\",'NNP'),\n",
    "             (\"discountinued\", 'VBD'),\n",
    "             (\"its\", 'PRP$'),\n",
    "             (\"Google\", 'NNP'),\n",
    "             (\"Translate\", 'NNP'),\n",
    "             (\"service\", \"NN\"),\n",
    "             (\"in\",\"IN\"),\n",
    "             (\"mainland\", \"JJ\"),\n",
    "             (\"China\", \"NNP\"),\n",
    "             (\"citing\", 'VBG'),\n",
    "             (\"low\",\"JJ\"),\n",
    "             (\"usage\", \"NN\"),\n",
    "             (\".\",\"SYM\")]\n",
    "print('Own tagging from Penn tag set: \\n')\n",
    "own_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK tagging: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Google', 'NNP'),\n",
       " ('discontinued', 'VBD'),\n",
       " ('its', 'PRP$'),\n",
       " ('Google', 'NNP'),\n",
       " ('Translate', 'NNP'),\n",
       " ('service', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('mainland', 'JJ'),\n",
       " ('China', 'NNP'),\n",
       " ('citing', 'VBG'),\n",
       " ('low', 'JJ'),\n",
       " ('usage', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_tagged = pos_tag(word_tokenize(news))\n",
    "print('NLTK tagging: \\n')\n",
    "news_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy Tagging:\n",
      "\n",
      "Google       PROPN      NNP      noun, proper singular\n",
      "discontinued VERB       VBD      verb, past tense\n",
      "its          PRON       PRP$     pronoun, possessive\n",
      "Google       PROPN      NNP      noun, proper singular\n",
      "Translate    PROPN      NNP      noun, proper singular\n",
      "service      NOUN       NN       noun, singular or mass\n",
      "in           ADP        IN       conjunction, subordinating or preposition\n",
      "mainland     NOUN       NN       noun, singular or mass\n",
      "China        PROPN      NNP      noun, proper singular\n",
      "citing       VERB       VBG      verb, gerund or present participle\n",
      "low          ADJ        JJ       adjective (English), other noun-modifier (Chinese)\n",
      "usage        NOUN       NN       noun, singular or mass\n",
      ".            PUNCT      .        punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "spacy_news = sp('Google discontinued its Google Translate service in mainland China citing low usage.')\n",
    "print('SpaCy Tagging:\\n')\n",
    "for word in spacy_news:\n",
    "    print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76cbc1d22d2ec03295cd5a8ae680c721667c569897428aaeeb69f9305902a57b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

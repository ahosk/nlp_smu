{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tag,word_tokenize,pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 1\n",
    "1. Run one of the part-of-speech (POS) taggers available in Python. \n",
    "> a. Find the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "\n",
    ">b. Find the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_sentence = 'Their plots were failing because of some important friends of the king.'\n",
    "short_setence = 'The panda eats, shoots and leaves.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Their', 'PRP$'),\n",
       " ('plots', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('failing', 'VBG'),\n",
       " ('because', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('trusted', 'JJ'),\n",
       " ('friends', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('king', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_tagged = pos_tag(word_tokenize(long_sentence))\n",
    "ls_tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('panda', 'NN'),\n",
       " ('eats', 'NNS'),\n",
       " (',', ','),\n",
       " ('shoots', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('leaves', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_tagged = pos_tag(word_tokenize(short_setence))\n",
    "ss_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 2\n",
    "\n",
    "2. Run a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "> a. Does it produce the same or different output? \n",
    "\n",
    "> b. Explain any differences as best you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their        PRON       PRP$     pronoun, possessive\n",
      "plots        NOUN       NNS      noun, plural\n",
      "were         AUX        VBD      verb, past tense\n",
      "failing      VERB       VBG      verb, gerund or present participle\n",
      "because      SCONJ      IN       conjunction, subordinating or preposition\n",
      "of           ADP        IN       conjunction, subordinating or preposition\n",
      "some         DET        DT       determiner\n",
      "important    ADJ        JJ       adjective (English), other noun-modifier (Chinese)\n",
      "friends      NOUN       NNS      noun, plural\n",
      "of           ADP        IN       conjunction, subordinating or preposition\n",
      "the          DET        DT       determiner\n",
      "king         NOUN       NN       noun, singular or mass\n",
      ".            PUNCT      .        punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "spacy_long = sp('Their plots were failing because of some important friends of the king.')\n",
    "for word in spacy_long:\n",
    "    print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          DET        DT       determiner\n",
      "panda        NOUN       NN       noun, singular or mass\n",
      "eats         VERB       VBZ      verb, 3rd person singular present\n",
      ",            PUNCT      ,        punctuation mark, comma\n",
      "shoots       NOUN       NNS      noun, plural\n",
      "and          CCONJ      CC       conjunction, coordinating\n",
      "leaves       NOUN       NNS      noun, plural\n",
      ".            PUNCT      .        punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "spacy_short = sp('The panda eats, shoots and leaves.')\n",
    "for word in spacy_short:\n",
    "    print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "# Part 3\n",
    "3. In a news article from this weekâ€™s news, find a random sentence of at least 10 words.\n",
    "> a. Looking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "\n",
    "> b. Now run the same sentences through both taggers that you implemented for questions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = 'Days later, there are residents of island communities cut off from the mainland, hundreds of thousands of people without power, and Floridians who have found themselves homeless'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD OWN TAGGING FROM: <url>https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html</url>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Days', 'NNS'),\n",
       " ('later', 'RB'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('residents', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('island', 'NN'),\n",
       " ('communities', 'NNS'),\n",
       " ('cut', 'VBD'),\n",
       " ('off', 'RP'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('mainland', 'NN'),\n",
       " (',', ','),\n",
       " ('hundreds', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('thousands', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('people', 'NNS'),\n",
       " ('without', 'IN'),\n",
       " ('power', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('Floridians', 'NNPS'),\n",
       " ('who', 'WP'),\n",
       " ('have', 'VBP'),\n",
       " ('found', 'VBN'),\n",
       " ('themselves', 'PRP'),\n",
       " ('homeless', 'JJ')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_tagged = pos_tag(word_tokenize(news))\n",
    "news_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days         NOUN       NNS      noun, plural\n",
      "later        ADV        RB       adverb\n",
      ",            PUNCT      ,        punctuation mark, comma\n",
      "there        PRON       EX       existential there\n",
      "are          VERB       VBP      verb, non-3rd person singular present\n",
      "residents    NOUN       NNS      noun, plural\n",
      "of           ADP        IN       conjunction, subordinating or preposition\n",
      "island       NOUN       NN       noun, singular or mass\n",
      "communities  NOUN       NNS      noun, plural\n",
      "cut          VERB       VBD      verb, past tense\n",
      "off          ADP        RP       adverb, particle\n",
      "from         ADP        IN       conjunction, subordinating or preposition\n",
      "the          DET        DT       determiner\n",
      "mainland     NOUN       NN       noun, singular or mass\n",
      ",            PUNCT      ,        punctuation mark, comma\n",
      "hundreds     NOUN       NNS      noun, plural\n",
      "of           ADP        IN       conjunction, subordinating or preposition\n",
      "thousands    NOUN       NNS      noun, plural\n",
      "of           ADP        IN       conjunction, subordinating or preposition\n",
      "people       NOUN       NNS      noun, plural\n",
      "without      ADP        IN       conjunction, subordinating or preposition\n",
      "power        NOUN       NN       noun, singular or mass\n",
      ",            PUNCT      ,        punctuation mark, comma\n",
      "and          CCONJ      CC       conjunction, coordinating\n",
      "Floridians   PROPN      NNPS     noun, proper plural\n",
      "who          PRON       WP       wh-pronoun, personal\n",
      "have         AUX        VBP      verb, non-3rd person singular present\n",
      "found        VERB       VBN      verb, past participle\n",
      "themselves   PRON       PRP      pronoun, personal\n",
      "homeless     ADJ        JJ       adjective (English), other noun-modifier (Chinese)\n"
     ]
    }
   ],
   "source": [
    "spacy_news = sp('Days later, there are residents of island communities cut off from the mainland, hundreds of thousands of people without power, and Floridians who have found themselves homeless')\n",
    "for word in spacy_news:\n",
    "    print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76cbc1d22d2ec03295cd5a8ae680c721667c569897428aaeeb69f9305902a57b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

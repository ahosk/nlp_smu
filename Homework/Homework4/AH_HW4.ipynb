{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4\n",
    "1. Run one of the part-of-speech (POS) taggers available in Python. \n",
    "> a. Find the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "\n",
    ">b. Find the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n",
    "2. Run a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "> a. Does it produce the same or different output?\n",
    "> b. Explain any differences as best you can.\n",
    "3. In a news article from this weekâ€™s news, find a random sentence of at least 10 words.\n",
    "> a. Looking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "> b. Now run the same sentences through both taggers that you implemented for questions \n",
    "\n",
    "\n",
    "1 and 2. Did either of the taggers produce the same results as you had created \n",
    "manually?\n",
    "> c. Explain any differences between the two taggers and your manual tagging as much as \n",
    "you can.\n",
    "\n",
    "\n",
    "<url>https://www.nltk.org/api/nltk.tag.html</url>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tag,word_tokenize,pos_tag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_sentence = 'Their plots were failing because of some trusted friends of the king.'\n",
    "short_setence = 'The horse raced past the barn fell.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('horse', 'NN'),\n",
       " ('raced', 'VBD'),\n",
       " ('past', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('barn', 'NN'),\n",
       " ('fell', 'VBD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_tagged = pos_tag(word_tokenize(long_sentence))\n",
    "ls_tagged\n",
    "ss_tagged = pos_tag(word_tokenize(short_setence))\n",
    "ss_tagged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76cbc1d22d2ec03295cd5a8ae680c721667c569897428aaeeb69f9305902a57b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
